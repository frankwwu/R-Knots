---
title: "TensorFlow with Keras Interface"
output: 
  html_document: 
    keep_md: yes
---

MNIST Example: recognizing handwritten digits from the MNIST dataset. Each digit is a 28 x 28 grayscale image. 

```{r setup, include=FALSE}
library(keras)
library(ggplot2)
library(imager)
library(flip)
```

## 1. Loading the Data

```{r}
# get MNIST dataset
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y

# input image dimensions
img_rows <- 28
img_cols <- 28
```

## 2. Displaying the Training Data in Images

```{r}
# display a few training images
par(mfrow = c(1, 3), pty = 's', mar = c(0, 2, 0, 2))
for (i in c(1, 2, 3)){
  m = matrix(unlist(x_train[i,,]), nrow = img_rows, byrow = TRUE)
  image(m, col=grey.colors(255), ylim=c(1, 0))
}
```

## 3. Preparing the Data

```{r}
input_shape = img_rows * img_cols

# convert the 3-d arrays into matrices. 28x28 images are flattened into length 784 vectors.
dim(x_train) <- c(nrow(x_train), input_shape)
dim(x_test) <- c(nrow(x_test), input_shape)

# convert the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1.
x_train <- x_train / 255
x_test <- x_test / 255

print(paste(nrow(x_train), " train samples"))
print(paste(nrow(x_test), " test samples"))
```


```{r}
# one-hot encode the y integer vectors into binary class matrices
num_classes = 10
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
```

## 4. Defining the Model

```{r}
# creating a sequential model and then adding layers
model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = "softmax")
```

## 5. Displaying the Details of the Model

```{r}
summary(model)
```

## 6. Compiling the Model 

```{r}
# compile the model with appropriate loss function, optimizer, and metrics
model %>% compile(loss = "categorical_crossentropy", optimizer = optimizer_rmsprop(), metrics = c("accuracy"))
```

## 7. Training the Model

```{r}
# Use the fit() function to train the model for 10 epochs using batches of 128 images
history <- model %>% fit(x_train, y_train, epochs = 15, batch_size = 128, validation_split = 0.2)
```

## 8. Display the Training Detail

```{r}
print(history$params$metrics)
plot(history)
```

## 9 Evaluating the Model

```{r}
# Evaluate the model's performance on the test data:
model %>% evaluate(x_test, y_test,verbose = 0)
```

## 10 Generate Predictions with the Test Data

```{r}
# Generate predictions on test data:
model %>% predict_classes(x_test)
```

## 11. Displaying the Test Data in Images

```{r}
# display a few test images
par(mfrow=c(1,3),pty='s',mar=c(0,2,0,2))
for (i in c(1,2,3)){
  m = matrix(unlist(x_test[i,]), nrow = 28, byrow = TRUE)
  image(m, col=grey.colors(255), ylim=c(1, 0))
}
```
